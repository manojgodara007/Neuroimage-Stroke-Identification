{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def load_images_from_folder(folder, label, image_size=(227, 227)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, image_size)  # Resize to match the input size\n",
    "            img = img / 255.0  # Normalize to [0, 1]\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Paths to your datasets\n",
    "path_to_stroke_images = r'D:\\Coding\\A Machine Learning-Based Diagnostic Model Using Neuroimages\\Brain_Data_Organised\\Stroke'\n",
    "path_to_normal_images = r'D:\\Coding\\A Machine Learning-Based Diagnostic Model Using Neuroimages\\Brain_Data_Organised\\Normal'\n",
    "\n",
    "# Load stroke and normal images\n",
    "stroke_images, stroke_labels = load_images_from_folder(path_to_stroke_images, 1)\n",
    "normal_images, normal_labels = load_images_from_folder(path_to_normal_images, 0)\n",
    "\n",
    "# Combine data\n",
    "X = np.array(stroke_images + normal_images)\n",
    "y = np.array(stroke_labels + normal_labels)\n",
    "\n",
    "# Expand dimensions to add channel information (1 channel for grayscale)\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 2s/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the VGG19 model pre-trained on ImageNet data\n",
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(227, 227, 3))\n",
    "\n",
    "# Define the layer from which you want to get the output\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)\n",
    "\n",
    "def extract_features(X):\n",
    "    # Because VGG19 expects three channels, we need to repeat our grayscale data\n",
    "    X_repeated = np.repeat(X, 3, axis=3)\n",
    "    features = model.predict(X_repeated)\n",
    "    return features\n",
    "\n",
    "# Extract features\n",
    "X_train_features = extract_features(X_train)\n",
    "X_val_features = extract_features(X_val)\n",
    "X_test_features = extract_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce the features' dimensionality\n",
    "pca = PCA(n_components=100)\n",
    "X_train_pca = pca.fit_transform(X_train_features.reshape(X_train_features.shape[0], -1))\n",
    "X_val_pca = pca.transform(X_val_features.reshape(X_val_features.shape[0], -1))\n",
    "X_test_pca = pca.transform(X_test_features.reshape(X_test_features.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\A Machine Learning-Based Diagnostic Model Using Neuroimages\\myenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.6107 - loss: 0.6701 - val_accuracy: 0.6507 - val_loss: 0.5856\n",
      "Epoch 2/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7561 - loss: 0.5025 - val_accuracy: 0.8747 - val_loss: 0.3174\n",
      "Epoch 3/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9598 - loss: 0.1759 - val_accuracy: 0.9227 - val_loss: 0.1912\n",
      "Epoch 4/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0428 - val_accuracy: 0.9413 - val_loss: 0.1358\n",
      "Epoch 5/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0163 - val_accuracy: 0.9413 - val_loss: 0.1295\n",
      "Epoch 6/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0090 - val_accuracy: 0.9360 - val_loss: 0.1469\n",
      "Epoch 7/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.9387 - val_loss: 0.1433\n",
      "Epoch 8/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0029 - val_accuracy: 0.9440 - val_loss: 0.1839\n",
      "Epoch 9/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0155 - val_accuracy: 0.9360 - val_loss: 0.1359\n",
      "Epoch 10/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9360 - val_loss: 0.1406\n",
      "Epoch 11/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9387 - val_loss: 0.1478\n",
      "Epoch 12/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5399e-04 - val_accuracy: 0.9440 - val_loss: 0.1505\n",
      "Epoch 13/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.3708e-04 - val_accuracy: 0.9440 - val_loss: 0.1504\n",
      "Epoch 14/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2545e-04 - val_accuracy: 0.9440 - val_loss: 0.1580\n",
      "Epoch 15/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4081e-04 - val_accuracy: 0.9440 - val_loss: 0.1608\n",
      "Epoch 16/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8208e-04 - val_accuracy: 0.9440 - val_loss: 0.1621\n",
      "Epoch 17/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.7372e-04 - val_accuracy: 0.9440 - val_loss: 0.1635\n",
      "Epoch 18/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5479e-04 - val_accuracy: 0.9440 - val_loss: 0.1658\n",
      "Epoch 19/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9052e-04 - val_accuracy: 0.9440 - val_loss: 0.1651\n",
      "Epoch 20/20\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8457e-04 - val_accuracy: 0.9440 - val_loss: 0.1668\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.9850 - loss: 0.0813\n",
      "Test Accuracy: 0.9760638475418091\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "def build_BiLSTM(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))\n",
    "    model.add(Bidirectional(LSTM(32)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X_train_lstm = X_train_pca.reshape((X_train_pca.shape[0], 1, X_train_pca.shape[1]))\n",
    "X_val_lstm = X_val_pca.reshape((X_val_pca.shape[0], 1, X_val_pca.shape[1]))\n",
    "X_test_lstm = X_test_pca.reshape((X_test_pca.shape[0], 1, X_test_pca.shape[1]))\n",
    "\n",
    "# Build and train the model\n",
    "model = build_BiLSTM((1, X_train_pca.shape[1]))\n",
    "history = model.fit(X_train_lstm, y_train, epochs=20, validation_data=(X_val_lstm, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_lstm, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step\n",
      "Accuracy: 0.976063829787234\n",
      "Precision: 0.9632352941176471\n",
      "Recall: 0.9703703703703703\n",
      "F1 Score: 0.966789667896679\n",
      "ROC AUC: 0.9954510527124635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict(X_test_lstm) > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test_lstm))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
